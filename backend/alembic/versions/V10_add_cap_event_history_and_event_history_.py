"""add cap event history and event history areas tables

Revision ID: V10
Revises: V9
Create Date: 2024-05-14 14:32:31.218471

"""
import json
import logging
import os.path
from typing import Sequence, Union

import sqlalchemy as sa
import sqlmodel
from alembic import op

# revision identifiers, used by Alembic.
revision: str = 'V10'
down_revision: Union[str, None] = 'V9'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None

schema = 'py_api'


LOGGER = logging.getLogger(__name__)

def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('cap_event_status',
    sa.Column('cap_event_status_id', sa.Integer(), nullable=False),
    sa.Column('cap_event_status', sqlmodel.sql.sqltypes.AutoString(), nullable=False),
    sa.PrimaryKeyConstraint('cap_event_status_id'),
    schema='py_api'
    )
    op.create_table('cap_event_history',
    sa.Column('cap_event_id', sa.Integer(), nullable=False),
    sa.Column('alert_id', sa.Integer(), nullable=False),
    sa.Column('cap_event_updated_date', sa.DateTime(), nullable=False),
    sa.Column('cap_event_hist_created_date', sa.DateTime(), nullable=False),
    sa.Column('alert_level', sa.Integer(), nullable=False),
    sa.Column('cap_event_status_id', sa.Integer(), nullable=False),
    sa.Column('cap_event_history_id', sa.Integer(), nullable=False),
    sa.ForeignKeyConstraint(['alert_id'], ['py_api.alerts.alert_id'], ),
    sa.ForeignKeyConstraint(['alert_level'], ['py_api.alert_levels.alert_level_id'], ),
    sa.ForeignKeyConstraint(['cap_event_id'], ['py_api.cap_event.cap_event_id'], ),
    sa.ForeignKeyConstraint(['cap_event_status_id'], ['py_api.cap_event_status.cap_event_status_id'], ),
    sa.PrimaryKeyConstraint('cap_event_history_id'),
    schema='py_api'
    )
    op.create_table('cap_event_areas_history',
    sa.Column('cap_event_area_history_id', sa.Integer(), nullable=False),
    sa.Column('cap_event_history_id', sa.Integer(), nullable=False),
    sa.Column('basin_id', sa.Integer(), nullable=False),
    sa.ForeignKeyConstraint(['basin_id'], ['py_api.basins.basin_id'], ),
    sa.ForeignKeyConstraint(['cap_event_history_id'], ['py_api.cap_event_history.cap_event_history_id'], ),
    sa.PrimaryKeyConstraint('cap_event_area_history_id'),
    schema='py_api'
    )
    op.add_column('cap_event', sa.Column('cap_event_status_id', sa.Integer(), nullable=False), schema='py_api')
    op.create_foreign_key(None, 'cap_event', 'cap_event_status', ['cap_event_status_id'], ['cap_event_status_id'], source_schema='py_api', referent_schema='py_api')
    op.drop_column('cap_event', 'cap_event_status', schema='py_api')
    # ### end Alembic commands ###

    # loading the statuses for the cap events
    cap_statuses_file = os.path.join(os.path.dirname(__file__), '..', 'data', 'cap_statuses.json')
    with open(cap_statuses_file, 'r') as cap_fh:
        cap_statuses = json.load(cap_fh)

    for status in cap_statuses:
        LOGGER.debug(f"status: {status}")
        cap_stat = status['cap_event_status']
        op.execute(f'INSERT INTO {schema}.cap_event_status(cap_event_status) VALUES (\'{cap_stat}\')')

def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('cap_event', sa.Column('cap_event_status', sa.VARCHAR(), autoincrement=False, nullable=False), schema='py_api')
    #op.drop_constraint(None, 'cap_event', schema='py_api', type_='foreignkey')
    op.drop_column('cap_event', 'cap_event_status_id', schema='py_api')
    op.drop_table('cap_event_areas_history', schema='py_api')
    op.drop_table('cap_event_history', schema='py_api')
    op.drop_table('cap_event_status', schema='py_api')
    # ### end Alembic commands ###
